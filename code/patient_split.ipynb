{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c73c702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 274 unique patients with at least one valid file.\n",
      "Total patients: 274\n",
      "  Train patients: 191\n",
      "  Val patients:   55\n",
      "  Test patients:  28\n",
      "\n",
      "Successfully saved patient splits to D:/VA/coding/project/cect/patient_splits.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "# FILE_CHECK_PATH = \"D:/VA/coding/project/cect/patient_data.csv\"\n",
    "OUTPUT_SPLIT_FILE = 'D:/VA/coding/project/cect/patient_splits.csv'\n",
    "TEST_RATIO = 0.1\n",
    "VAL_RATIO = 0.2\n",
    "RANDOM_SEED = 42\n",
    "# ---------------------\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- Configuration ---\n",
    "FILE_CHECK_PATH = 'D:/VA/coding/project/cect/file_check.csv'       # Input: The file with 'label'\n",
    "PATIENT_DATA_PATH = 'D:/VA/coding/project/cect/patient_data.csv'   # Input: The file linking patient_id to file_name\n",
    "# ---------------------\n",
    "\n",
    "def run_patient_split():\n",
    "    \"\"\"\n",
    "    Reads file_check.csv to find valid files, maps them to\n",
    "    patient_ids using patient_data.csv, splits the unique\n",
    "    patients, and saves this mapping to patient_splits.csv.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Load both CSVs ---\n",
    "    try:\n",
    "        df_check = pd.read_csv(FILE_CHECK_PATH)\n",
    "        df_patient = pd.read_csv(PATIENT_DATA_PATH)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find a required file. {e}\", file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    # --- 2. Get all valid file names ---\n",
    "    # Get all rows from file_check.csv where label is True\n",
    "    valid_files_df = df_check[df_check['label'] == True]\n",
    "    \n",
    "    # Create a set of all valid file names for fast lookup.\n",
    "    # We will need to handle .nii vs .nii.gz mismatches.\n",
    "    valid_file_names_set = set()\n",
    "    for f in valid_files_df['file_name']:\n",
    "        valid_file_names_set.add(f)\n",
    "        if f.endswith('.nii.gz'):\n",
    "            valid_file_names_set.add(f.replace('.nii.gz', '.nii')) # Add .nii version\n",
    "        elif f.endswith('.nii'):\n",
    "            valid_file_names_set.add(f + '.gz') # Add .nii.gz version\n",
    "            \n",
    "    if not valid_file_names_set:\n",
    "        print(\"Error: No valid files found (label == True) in file_check.csv\", file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    # --- 3. Map valid files to patients ---\n",
    "    \n",
    "    # Get the base file name from 'ct_path' in patient_data.csv\n",
    "    # e.g., 'ct_files/P0001_ct_P.nii.gz' -> 'P0001_ct_P.nii.gz'\n",
    "    df_patient['file_name_base'] = df_patient['ct_path'].apply(lambda x: os.path.basename(str(x)))\n",
    "    \n",
    "    # Check which rows in patient_data.csv have a file name that is in our valid set\n",
    "    df_patient['is_valid'] = df_patient['file_name_base'].apply(lambda x: x in valid_file_names_set)\n",
    "    \n",
    "    # Get all rows for patients that have at least one valid file\n",
    "    valid_patient_rows = df_patient[df_patient['is_valid']]\n",
    "    \n",
    "    # --- 4. Get unique patients from this valid list ---\n",
    "    valid_patients = sorted(list(valid_patient_rows['patient_id'].unique()))\n",
    "    \n",
    "    print(f\"Found {len(valid_patients)} unique patients with at least one valid file.\")\n",
    "    if not valid_patients:\n",
    "        print(\"No patients found. Check file name matching logic between CSVs.\", file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    # --- 5. Perform the splits on the patient list ---\n",
    "    \n",
    "    # 1. Split into (train+val) and (test)\n",
    "    train_val_patients, test_patients = train_test_split(\n",
    "        valid_patients,\n",
    "        test_size=TEST_RATIO,\n",
    "        random_state=RANDOM_SEED,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # 2. Calculate the correct validation ratio for the remaining data\n",
    "    val_ratio_in_train_val = VAL_RATIO / (1.0 - TEST_RATIO)\n",
    "    \n",
    "    # 3. Split (train+val) into (train) and (val)\n",
    "    train_patients, val_patients = train_test_split(\n",
    "        train_val_patients,\n",
    "        test_size=val_ratio_in_train_val,\n",
    "        random_state=RANDOM_SEED,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Total patients: {len(valid_patients)}\")\n",
    "    print(f\"  Train patients: {len(train_patients)}\")\n",
    "    print(f\"  Val patients:   {len(val_patients)}\")\n",
    "    print(f\"  Test patients:  {len(test_patients)}\")\n",
    "    \n",
    "    # --- 6. Create and save the split DataFrame ---\n",
    "    \n",
    "    # Assign each patient to their split\n",
    "    train_df = pd.DataFrame({'patient_id': train_patients, 'split': 'train'})\n",
    "    val_df = pd.DataFrame({'patient_id': val_patients, 'split': 'val'})\n",
    "    test_df = pd.DataFrame({'patient_id': test_patients, 'split': 'test'})\n",
    "    \n",
    "    # Combine them into one file\n",
    "    split_df = pd.concat([train_df, val_df, test_df]).reset_index(drop=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    split_df.to_csv(OUTPUT_SPLIT_FILE, index=False)\n",
    "    \n",
    "    print(f\"\\nSuccessfully saved patient splits to {OUTPUT_SPLIT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_patient_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "682ee19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 274 unique patients with at least one valid file.\n",
      "\n",
      "Successfully created master split file: D:/VA/coding/project/cect/file_splits.csv\n",
      "This file contains all valid files and their assigned split.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- Configuration ---\n",
    "OUTPUT_FILE = 'D:/VA/coding/project/cect/file_splits.csv'\n",
    "TEST_RATIO = 0.1\n",
    "VAL_RATIO = 0.2\n",
    "RANDOM_SEED = 42\n",
    "# ---------------------\n",
    "\n",
    "def create_master_split_file():\n",
    "    \"\"\"\n",
    "    Combines file_check, patient_data, and a new patient split\n",
    "    to create a single master CSV mapping valid files to their\n",
    "    train/val/test split.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Load patient_data and file_check ---\n",
    "    try:\n",
    "        df_patient = pd.read_csv(PATIENT_DATA_PATH)\n",
    "        df_check = pd.read_csv(FILE_CHECK_PATH)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find a required file. {e}\", file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    # --- 2. Get set of all valid file names ---\n",
    "    df_check_valid = df_check[df_check['label'] == True]\n",
    "    valid_file_names_set = set()\n",
    "    for f in df_check_valid['file_name']:\n",
    "        valid_file_names_set.add(f)\n",
    "        if f.endswith('.nii.gz'):\n",
    "            valid_file_names_set.add(f.replace('.nii.gz', '.nii'))\n",
    "        elif f.endswith('.nii'):\n",
    "            valid_file_names_set.add(f + '.gz')\n",
    "\n",
    "    # --- 3. Filter patient_data for valid files ---\n",
    "    # Get base file name\n",
    "    df_patient['file_name'] = df_patient['ct_path'].apply(lambda x: os.path.basename(str(x)))\n",
    "    \n",
    "    # Check if the file is in our valid set\n",
    "    df_patient['is_valid'] = df_patient['file_name'].apply(lambda x: x in valid_file_names_set)\n",
    "    \n",
    "    # Keep only the rows that are valid\n",
    "    df_valid_files = df_patient[df_patient['is_valid']].copy()\n",
    "    \n",
    "    if df_valid_files.empty:\n",
    "        print(\"Error: No files in patient_data.csv matched a valid file in file_check.csv\", file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    # --- 4. Get unique patients from this valid list ---\n",
    "    valid_patients = sorted(list(df_valid_files['patient_id'].unique()))\n",
    "    print(f\"Found {len(valid_patients)} unique patients with at least one valid file.\")\n",
    "\n",
    "    # --- 5. Perform the patient splits ---\n",
    "    train_val_patients, test_patients = train_test_split(\n",
    "        valid_patients, test_size=TEST_RATIO, random_state=RANDOM_SEED, shuffle=True\n",
    "    )\n",
    "    val_ratio_in_train_val = VAL_RATIO / (1.0 - TEST_RATIO)\n",
    "    train_patients, val_patients = train_test_split(\n",
    "        train_val_patients, test_size=val_ratio_in_train_val, random_state=RANDOM_SEED, shuffle=True\n",
    "    )\n",
    "\n",
    "    # --- 6. Create the patient-to-split mapping ---\n",
    "    train_df = pd.DataFrame({'patient_id': train_patients, 'split': 'train'})\n",
    "    val_df = pd.DataFrame({'patient_id': val_patients, 'split': 'val'})\n",
    "    test_df = pd.DataFrame({'patient_id': test_patients, 'split': 'test'})\n",
    "    \n",
    "    split_map_df = pd.concat([train_df, val_df, test_df])\n",
    "\n",
    "    # --- 7. Merge the split info with our valid file list ---\n",
    "    # This assigns 'train', 'val', or 'test' to every valid file\n",
    "    # based on its patient_id\n",
    "    df_final = df_valid_files.merge(split_map_df, on='patient_id', how='left')\n",
    "\n",
    "    # --- 8. Save the final, clean file ---\n",
    "    # We only need the file_name and its split\n",
    "    output_columns = ['patient_id', 'file_name', 'split']\n",
    "    df_final_to_save = df_final[output_columns].drop_duplicates()\n",
    "    \n",
    "    df_final_to_save.to_csv(OUTPUT_FILE, index=False)\n",
    "    \n",
    "    print(f\"\\nSuccessfully created master split file: {OUTPUT_FILE}\")\n",
    "    print(\"This file contains all valid files and their assigned split.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_master_split_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70e8320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
